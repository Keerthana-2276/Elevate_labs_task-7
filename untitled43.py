# -*- coding: utf-8 -*-
"""Untitled43.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NjksnIz01zlqdIEVj0eoW5kdgQoZmGYD
"""

# Import libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from mlxtend.plotting import plot_decision_regions

# Step 1: Load 2D binary classification dataset
X, y = datasets.make_classification(
    n_samples=300, n_features=2, n_redundant=0,
    n_clusters_per_class=1, random_state=42
)

# Visualize raw dataset
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k')
plt.title("Raw Binary Classification Data")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 2: Train-test split and scale
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 3: SVM with Linear Kernel
svm_linear = SVC(kernel='linear', C=1)
svm_linear.fit(X_train_scaled, y_train)

# Visualize linear decision boundary
plt.figure(figsize=(6, 4))
plot_decision_regions(X_train_scaled, y_train, clf=svm_linear, legend=2)
plt.title("SVM with Linear Kernel")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 4: SVM with RBF Kernel
svm_rbf = SVC(kernel='rbf', C=1, gamma='scale')
svm_rbf.fit(X_train_scaled, y_train)

# Visualize RBF decision boundary
plt.figure(figsize=(6, 4))
plot_decision_regions(X_train_scaled, y_train, clf=svm_rbf, legend=2)
plt.title("SVM with RBF Kernel")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# Step 5: Hyperparameter tuning (RBF kernel)
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 0.1, 1, 10]
}
grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5)
grid.fit(X_train_scaled, y_train)

print("Best Parameters (RBF Kernel):", grid.best_params_)
print("Best Cross-Validation Score:", grid.best_score_)

# Step 6: Evaluate best model using cross-validation
best_model = grid.best_estimator_
cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5)
print("\nCross-Validation Scores:", cv_scores)
print("Mean Accuracy:", cv_scores.mean())

# Final performance on test data
y_pred = best_model.predict(X_test_scaled)
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))